{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: <UTF-8> -*-\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "with open(\"199801_clear.txt\", \"r\", encoding='gbk') as f:\n",
    "    txt = f.readlines()\n",
    "\n",
    "passages = []\n",
    "d = {}\n",
    "for line in txt:\n",
    "    #split paragraphs by '\\n'\n",
    "    if line == '\\n':\n",
    "        if len(d) > 0:\n",
    "            passages.append(copy.deepcopy(d))\n",
    "        d = {}\n",
    "        continue\n",
    "    \n",
    "    #split words by spaces & calculating words frequency\n",
    "    line_list = line.split('  ')\n",
    "    for term in line_list:\n",
    "        if term[-2:] in ['/w', '/m', '\\n', '/u', '/r', '/c', '/p', '/q', '/d']:\n",
    "            continue\n",
    "        d[term] = d.get(term,0)+1\n",
    "        \n",
    "passages.append(copy.deepcopy(d))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TF(passage, word):\n",
    "    return passage[word] / sum(passage.values())\n",
    "\n",
    "def get_IDF(passages, word):\n",
    "    return len(passages) / (1 + sum([1 for p in passages if word in p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_words(passage, passages, key_words_n = 20):\n",
    "    tfidf_sum = {word:get_TF(passage, word) * get_IDF(passages, word) for word in passage}\n",
    "    return dict(sorted(tfidf_sum.items(), key=lambda x:x[1], reverse=True)[:key_words_n])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "passages_keyword = [get_key_words(p, passages, 20) for p in passages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_dot(d1, d2):\n",
    "    return sum([d1.get(k, 0) * d2.get(k, 0) for k in d1])\n",
    "\n",
    "def get_norm(vec):\n",
    "    return math.sqrt(sum([num**2 for num in vec]))\n",
    "\n",
    "def get_cosine_similarity(p1, p2):\n",
    "    return get_dict_dot(p1, p2) / (get_norm(p1.values()) * get_norm(p2.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(passages_keyword)\n",
    "similarity_matrix = np.zeros([l, l])\n",
    "for i in range(l):\n",
    "    for j in range(i+1, l):\n",
    "        similarity_matrix[i][j] = get_cosine_similarity(passages_keyword[i], passages_keyword[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026246728335506828"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][1]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b7085cec86a6a118bc52696a5a18e85491c19109cf3e9c1006f4aab9b757628"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
